# 交通灯控优化任务配置文件 - PPO版本
task_name: "交通灯控优化任务"
task_type: "traffic_light_optimization"

# 城市设置
city: "Manha"

# 数据文件路径
data_paths:
  route_file: "Experiment/Opti_new_Manha/random4.xml"
  real_flow_file: "Experiment/Opti_new_Manha/Realflow.xml"
  original_net_file: "Experiment/Opti_new_Manha/Manha_new.net.xml"
  decisions_data_pkl: "pkl/Only_ppo_opti_Manha_tl_phase_result.pkl"
  lane_averages_pkl: "pkl/Only_ppo_opti_Manha_lane_averages.pkl"
  reward_static_pkl: "pkl/reward_static_all_Manha_single_ppo.pkl"

# RL算法参数
rl_config:
  algorithm: "ppo"
  episodes: 30
  end_time: 600
  cal_reward_circle: 5
  action_interval: 5
  learning_start_time: 500
  update_model_rate: 5
  update_target_rate: 100
  checkpoint_dir: "test_pth/rl_single_stat_manus_ppo"
  use_gui: false

  # PPO特定参数（TODO：请根据实际训练经验填写）
  ppo_params:
    lr: 0.0003
    batch_size: 64
    # clip_range: 0.2
    # n_epochs: 10
    # entropy_coef: 0.01

  # 奖励配置
  reward_config:
    local_weight: 0.75
    rl_group_weight: 0.15
    global_weight: 0.10
    use_local_queue: true
    use_local_waiting: true
    use_local_throughput: true

# 交通灯IDs（如果为空则自动检测）
rl_tls_ids: ['cluster_12187433924_12187433926_42428438_7741546977_']
rl_tls_ids_all: True
# 非RL策略
non_rl_policy: "greedy"

# 训练模式
training: true
