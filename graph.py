"""
LangGraph Agent for MCP Tools
é€‚é… agent-chat-ui çš„ MCP Agent
"""

from tool.getroadnetwork import *

import asyncio
import json
import logging
import os
from typing import Any, Dict, List
from langgraph.prebuilt import create_react_agent
from langchain_deepseek import ChatDeepSeek
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('E:\BaiduDisk\LangChainå…¬å¼€è¯¾\SumoManus\lang_ui\environment.env')

class Configuration:
    """è¯»å–é…ç½®"""
    def __init__(self) -> None:
        self.api_key: str = os.getenv("LLM_API_KEY") or ""
        self.langsmith_api_key: str = os.getenv("LANGCHAIN_API_KEY") 
        self.base_url: str | None = os.getenv("BASE_URL")
        self.model: str = os.getenv("MODEL") or "deepseek-chat"
        if not self.api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° LLM_API_KEYï¼Œè¯·åœ¨ .env ä¸­é…ç½®")

    @staticmethod
    def load_servers(file_path: str = "servers_config.json") -> Dict[str, Any]:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f).get("mcpServers", {})
        except FileNotFoundError:
            logging.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {file_path} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç©ºé…ç½®")
            return {}
        except json.JSONDecodeError as e:
            logging.error(f"âŒ é…ç½®æ–‡ä»¶ {file_path} JSON æ ¼å¼é”™è¯¯: {e}")
            return {}


def create_agent():
    
    
    from langchain_tavily import TavilySearch
    search_tool = TavilySearch(max_results=5, topic="general", api_key=os.getenv("TAVILY_API_KEY"))
    tools = [create_sumo_net_from_bbox,search_tool]
    """åˆ›å»º LangGraph agent"""
    cfg = Configuration()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["DEEPSEEK_API_KEY"] = cfg.api_key
    if cfg.base_url:
        os.environ["DEEPSEEK_API_BASE"] = cfg.base_url
    
    
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = ChatDeepSeek(model="deepseek-chat", api_key=cfg.api_key)
    from langgraph.prebuilt import create_react_agent
    
    
    # è¯»å–æç¤ºè¯
    try:
        with open("agent_prompts.txt", "r", encoding="utf-8") as f:
            prompt = f.read()
    except FileNotFoundError:
        prompt = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·å¤„ç†å„ç§ä»»åŠ¡ã€‚"
    
    
    agent = create_react_agent(model=model, tools=tools, prompt=prompt)

    
    return agent

# # åˆ›å»ºå¹¶å¯¼å‡º graph å¯¹è±¡ - è¿™æ˜¯ agent-chat-ui éœ€è¦çš„
# graph = asyncio.run(create_agent())

# # ç”¨äºç›´æ¥è¿è¡Œçš„å‡½æ•°
# async def run_chat_loop():
#     """å‘½ä»¤è¡ŒèŠå¤©å¾ªç¯ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
#     agent = await create_agent()
    
#     print("\nğŸ¤– MCP Agent å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    
#     config = {"configurable": {"thread_id": "1"}}
    
#     while True:
#         user_input = input("\nä½ : ").strip()
#         if user_input.lower() == "quit":
#             break
        
#         try:
#             result = await agent.ainvoke(
#                 {"messages": [{"role": "user", "content": user_input}]},
#                 config
#             )
#             print(f"\nAI: {result['messages'][-1].content}")
#         except Exception as exc:
#             print(f"\nâš ï¸  å‡ºé”™: {exc}")

# if __name__ == "__main__":
#     logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
#     asyncio.run(run_chat_loop())